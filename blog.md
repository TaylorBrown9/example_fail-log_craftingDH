Week one - 

using the command line in DH Box went over well. I had success using all commands up until xercise 4.7. I was able to fork another persons repository and make a pull request in GitHub but when I needed to enter commands in DH Box for this I continued to get a message saying fatal:not a git repository. I am still unable to figure this one out. 
Using Dillinger - I could not open it on the first day that I tried but it is now working. I wrote about an annotation and entered the html for a picture but the picture did not show. After watching the video for this in the workbook it seems that the website has been updated so I could not follow the steps as it is looking completely different now. 


Week two-

I am finding the exercises are becoming tougher. The videos are helpful and I can (usually) resolve the problem I face after watching. I ran into some trouble converting images with both the command line and R studio. After posting in Slack I was given advice and was able to get the command line working. I annotated where I ran into trouble. I am still unsure if I am doing my fail log correctly, but I changed the format in which I am using it in hopes that I can reference back to it, but I am finding it much easier to reference back to the previous weeks' module when stuck. I am finding some annotations from last year helpful as well. Some people have annotated similar issues I have faced and there has been a way to over come it in a reply to the annotation.

This week I read the article about Bentham. I found many aspects of this article similiar to this current course. The article mentioned training videos and a social space for individuals to post questions/feedback. I find that these videos and the Slack conversations to be the main reason that I am able to get through most exercises. Without these I would be very lost. I am glad that our course does not use a 'Benthamometer' as I would find that seeing a leaderboard would cause stress onto an already somewhat stressful course. I feel as though this course causes the most stress because I am doing many things with a computer that I have never done before so everything is a new experience leaving any errors I encounter to be unsolvable on my own. I am also finding that when I am reading the articles I am only seeing annotations from last year. I am responding to them as I had this issue last week as well. I am unsure if I am maybe looking in the wrong spot or if I am in fact the only one so far annotating on the readings. 


Week three - 

This week I found the modules easier to understand and follow, but somehow managed to make a mistake somewhere whoch resulted in my chart only having one column when it was uploaded to open refine and had a blank line inbetween each name. Iam unsure how this happened but saw that there was annotation from last year's class about this happening to them - https://hyp.is/uiQ4GGhqEeiurpci9xw7bQ/workbook.craftingdigitalhistory.ca/supporting%20materials/open-refine/. I tried to redownload the file from DH box and uploading it again. With the first attempt to upload I recieved an error message but the second was successful and no longer had the blank lines inbetween each name but still had only one column. I left it as just one column and continued to follow the instructions and playing around with the site. I found the first exercise of this module to be quite time consuming to erase all of the unwanted data in Nano. After selecting text for about an hour in DH box Nano I then saved and tried to use Sublime text editor. This seemed to work a little bit quicker but still took a bit of time. It was taking so long in Nano that I began to think that I was doing something wrong but noticed an annoation from last year with someone wondering the same thing for the same reason - https://hyp.is/8vwgTmhZEeifQAPzkOL1DQ/workbook.craftingdigitalhistory.ca/supporting%20materials/regexex/. 

For this week's reading I chose to read Blevins, Mining and Mapping the Production of Space A View of the World from Houston. It was interesting to read the viewpoints on digitalized newspapers that are often used in today's society. it was interesting to read how an online newspaper is characterized as stated in the reading " Digitized newspapers are inherently messy sources. They often resemble a jumbled bag of mistake-ridden words as much as neatly segmented columns of text." Often places are not recognized or stated in some newspapers because of them being "small towns" that people do not know about. Information like this is often lost or hidden which I have also noticed when reading articles about the small town that I live in. My town is often described as "a small town west of Ottawa" or "a small town about an hour outside of Ottawa." It hasnt been until recent that I have noticed the name of my town being used more due to Tweed moving in. https://hyp.is/QDKynIL4EemJ0XcuEdx17Q/web.stanford.edu/group/spatialhistory/cgi-bin/site/pub.php?id=93. Although it would seem that before digitalized newspapers were invented, people having to wait for the print cycle in order to recieve information on current events would miss out on information, I am not entirley conviced this is true. With digital newspapers articles can be created and sent out reaching thousands/millions within minutes but often information is not yet varified and accurate resulting in many updated articles needing to come afterwords to change facts. Not all those who read the first article see updated ones leading to "fake news" or uninformed opinions. With the wait for the print cycle I would assume that these changes would be made and information would be quite accurate. https://hyp.is/cvL7fIL6Eem3gx_6wPHJPw/web.stanford.edu/group/spatialhistory/cgi-bin/site/pub.php?id=93 


Week Five-

I found that the exercises I did this week were very easy to follow, but I did not have success with the mapping exercise. I was able to create an account and upload a map fairly easily. I ran into some error codes regarding 'file name' when trying to upload the map but I was easily able to fix the issue on my own and get it uploaded to the site. I ran into a lot of issues trying to pin point the same spot on both maps. The default on the map when I went to recitify it went to a map of a place in Africa. I then moved the map to Quebec but was not able to find the same point. I attempted a different map and the same thing occured. I watched the videos to see how the rest of the exercise would have went if this was successful in order to understand the full exercise. During another exercise I was able to easily zip a file in the DH box, save it to my computer and follow the rest of the directions successfully and easily. 

This week I read the article on Metadata. I found this article to be very interesting as I am also taking a statistics class. The way the data is collected without human interaction but can still be used in a ethical way with the mention of some freedom enroachment is interesting. My first annotation was about this. https://hyp.is/VU-LuolQEemmhDvwuFJgaA/kieranhealy.org/blog/archives/2013/06/09/using-metadata-to-find-paul-revere/. With the metadata being collected to see suspected terrorists, this word needs to be used lightly rather than in a rash manner as this word can have devistating consequences if used without any supporting data. https://hyp.is/bV07tolREemiazMWHALr4Q/kieranhealy.org/blog/archives/2013/06/09/using-metadata-to-find-paul-revere/. Although the collection of data can be done in what seems like a very accurate way, it is always subject to human error whether done digitally or not. If the collection is done only in a digital way, it can also be vulnerable to other errors. https://hyp.is/2iAgYIlREemc8F-LtDxSkw/kieranhealy.org/blog/archives/2013/06/09/using-metadata-to-find-paul-revere/. With advancements being made in technology everyday, these errors and vulnerability will hopefully decrease. 


Final Week-

This week I was very thankful for the Slack chat. I relied on this many times to discuss the Capstone Exercise wth Dr. Graham and other classmates. After discussing and posting a few questions the assignment became clearer but I am not confident that I am displaying the research correctly. I asked in Slack if we needed a domain if we chose option 2 and Dr. Graham informed me that forking the assignment would be sufficient. I created a new file within the original and posted all of my updated research that I collected there. I am hoping this is correct. I also uploaded part two of the assignment that was the reflection of the course within it's own file in the original assignment as well. I was successful in finding new data and using Google Trends for the first time. Prior to this assignment I did not know that Google Trends even existed. I found this assignment challenging in the sense that I was not confident in the exact outcome we were supposed to have but I enjoyed the challenges that this assignment and the entire course has given me. 
